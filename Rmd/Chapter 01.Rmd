---
title: "PLAN for Chapter 1. Methodology for fitting ODE epidemic models"
subtitle: "This RMarkdown is a template as initially outlined in the progress report. Each task will be outlined and then followed by a code block to be completed."
output:
  html_notebook:
    number_sections: true
---

# Introduction

When calibrating their vivax population transmission models, White and Champagne lack longitudinal time series data and are forced to make equilibrium assumptions at a point in time (initially from Griffin from his 2014 P.f model). Here, derivatives are set to zero and the equations solved for unknowns. In the case of Champagne, the transmission rate $\lambda$ so that force of infection is $\lambda$ multiplied by the sum of infectious compartments $\sum{I}$.

This assumption does not hold for areas with moderate to strong seasonality and long-term trends. This document demonstrates the standard implementation of dynamic ODE parameter-fitting methods applied to the White/Champagne style model and extends the form of the model (and its corresponding parameter estimation routine) to provide increasingly flexible relaxations to the original uses of the White/Champagne model. The end result will be a model and fitting routine that is flexible enough to reflect vivax epidemics in non-stationary regions, unlike the original implementation.

[...]

# Methods

Stan and posterior sampling will be used for all analyses.

```{r setup}
library(tidyverse)
library(rstan)
library(rstansim)
options(mc.cores = 8)
rstan_options(auto_write = TRUE)

years = 365.25
annual_subdivisions = 12
```

## Model implementation

We begin with extending Champagne's 2022 model for tropical vivax to include seasonality.

First we implement and verify the parameter recovery ability of Stan with the Champagne model as published in 2022.

```{r}
model_champagne2022 = "champagne2022.stan"
stan_model_champagne2022 = stan_model(model_champagne2022)

# perform simulation study
# max_time = 1 * years
dt = years/annual_subdivisions
# t = seq(years/annual_subdivisions, max_time, annual_subdivisions)
t0 = -10*years
t = seq_len(5*12) * dt
n_times = length(t)
# time series of cases
N = 1000 # population size
n_iter = 1000

#initial conditions
I_init = 0.1
y0 = c(Il=0, I0=I_init, Sl=0, S0=1-I_init, CumulativeInfections=0)

# constants for Stan
data_consts = list(n_times = n_times+1,
                   y0 = y0,
                   t0 = t0,
                   ts = seq_len(n_times+1) * dt,
                   N = N,
                   cases = rep(99999, n_times+1),
                   r = 1./60, # r
                   gammal = 1./223, # gammal
                   f = 1./72, # f
                   alpha = 0.21, # alpha
                   beta = 0.66, # beta
                   rho = 0.21, # rho
                   delta = 0
)

# Generate synthetic observations
real_params = list(lambda=0.01, phi_inv=0.1)
synth_data = simulate_data(
  file = model_champagne2022,
  data_name = "dummy_data",
  input_data = data_consts,
  param_values = real_params,
  vars = c("ts", "sim_cases")
)
synth_data_rds = readRDS(synth_data$datasets[1])
indx <- sapply(synth_data_rds, length)
synth_df = lapply(synth_data_rds, function(x) {length(x) = max(indx); x}) %>%
  as.data.frame() %>%
  drop_na()


ggplot(synth_df, aes(x=ts, y=cases)) +
  geom_point()
```

```{r}
# Fit data
data = data_consts
data$n_times = n_times
data$ts = synth_df$ts
data$cases = synth_df$cases

optim = optimizing(stan_model_champagne2022,
                   data = data)
theta_init = as.list(optim$par[c("lambda", "phi_inv")]) # optimisation results
plot_data = optim$par %>%
  as.data.frame() %>%
  bind_cols(rownames(.), .) %>%
  setNames(c("name", "value")) %>%
  as_tibble() %>%
  mutate(index_i = name %>% str_extract("(?<=\\[)[0-9]+") %>% as.numeric(),
         time = t[index_i],
         index_j = name %>% str_extract("(?<=,)[0-9]+") %>% as.numeric(),
         compartment = names(y0)[index_j],
         variable = name %>% str_remove("\\[.*")) %>%
  mutate(variable = coalesce(compartment, variable))

plot_data %>%
  drop_na(time) %>%
  ggplot(aes(x=time, y=value, color=variable, group=variable)) +
  geom_line() +
  facet_wrap(vars(variable), scales="free_y") +
  coord_cartesian(ylim = c(0, NA))
```

```{r}
n_chains = 4
fit = sampling(stan_model_champagne2022,
               data = data,
               iter = n_iter,
               chains = n_chains,
               init = rep(list(theta_init), n_chains), # Start from MLE solution
               seed = 0)

pairs(fit, pars=c("lambda", "phi_inv"))

smr_pred <- cbind(as.data.frame(
  summary(
    fit,
    pars = "sim_cases",
    probs = c(0.05, 0.5, 0.95)
  )$summary),
  t=t[1:(n_times-1)], cases=synth_df$cases[1:(n_times-1)])
colnames(smr_pred) <- make.names(colnames(smr_pred)) # to remove % in the col names

c_posterior = "blue"
ggplot(smr_pred, mapping = aes(x = t)) +
  geom_ribbon(aes(ymin = X5., ymax = X95.), fill = c_posterior, alpha = 0.35) +
  geom_line(mapping = aes(y = X50.), color = c_posterior) + 
  geom_point(mapping = aes(y = cases)) +
  labs(x = "Day", y = "Cases") +
  coord_cartesian(ylim = c(0, NA))
```

```{r}
params_extract = rstan::extract(fit, c("lambda", "phi_inv")) %>%
  lapply(as.numeric) %>%
  as_tibble()
real_params_df = as.data.frame(real_params) %>%
  pivot_longer(everything())
params_extract %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = value)) +
  geom_density(color="steelblue", fill="steelblue", alpha=0.75) +
  geom_vline(data=real_params_df, aes(xintercept=value), linetype="dashed") +
  facet_wrap(vars(name), scales = "free") +
  labs(title = "Re-estimated posterior densities",
       subtitle = "Dashed line: simulated value")
```

```{r}
ts_extract = rstan::extract(fit, "sim_cases")[[1]]
ix = sample(seq_len(dim(ts_extract)[1]), 1000)
ts_sample = as_tibble(t(ts_extract[ix,])) %>%
  mutate(j = row_number()) %>%
  pivot_longer(-j, names_to = "trace")

ggplot(ts_sample, aes(x=j, y=value, grou=trace)) +
  geom_line(alpha = 0.1)

ts_extract = rstan::extract(fit, "incidence")[[1]]
ix = sample(seq_len(dim(ts_extract)[1]), 1000)
ts_sample = as_tibble(t(ts_extract[ix,])) %>%
  mutate(j = row_number()) %>%
  pivot_longer(-j, names_to = "trace")

ggplot(ts_sample, aes(x=j, y=value, grou=trace)) +
  geom_line(alpha = 0.1) +
  coord_cartesian(ylim = c(0, 200))
```

Then we modify the Champagne model to include seasonality (as postulated in 2022) and verify again.

```{r}
model_champagne2022_seasonal = "champagne2022_seasonal.stan"
stan_model_champagne2022_seasonal = stan_model(model_champagne2022_seasonal)

# perform simulation study
# constants for Stan
data_consts = list(n_times = n_times+1,
                   y0 = y0,
                   t0 = t0,
                   ts = seq_len(n_times+1) * dt,
                   N = N,
                   cases = rep(99999, n_times+1),
                   r = 1./60, # r
                   gammal = 1./223, # gammal
                   f = 1./72, # f
                   alpha = 0.21, # alpha
                   beta = 0.66, # beta
                   rho = 0.21, # rho
                   delta = 0,
                   eps = 0,
                   kappa = 1,
                   phase = 0
)

# Generate synthetic observations
real_params = list(lambda=0.001, phi_inv=0.1)
synth_data = simulate_data(
  file = model_champagne2022_seasonal,
  data_name = "dummy_data",
  input_data = data_consts,
  param_values = real_params,
  vars = c("ts", "sim_cases", "susceptible")
)
synth_data_rds = readRDS(synth_data$datasets[1])
indx <- sapply(synth_data_rds, length)
synth_df = lapply(synth_data_rds, function(x) {length(x) = max(indx); x}) %>%
  as.data.frame() %>%
  drop_na()

synth_df %>%
  pivot_longer(-ts) %>%
  ggplot(aes(x=ts, y=value)) +
  geom_line() +
  facet_wrap(vars(name), scales="free_y")

# Fit data
# Edit data with generated values
data = data_consts
data$n_times = n_times
data$ts = synth_df$ts
data$cases = synth_df$cases

optim = optimizing(stan_model_champagne2022,
                   data = data)
theta_init = as.list(optim$par[c("lambda", "phi_inv")]) # optimisation results
```

```{r}
fit = sampling(stan_model_champagne2022_seasonal,
               data = data,
               iter = n_iter,
               chains = n_chains,
               init = rep(list(theta_init), n_chains), # Start from MLE solution
               seed = 0)

pairs(fit, pars=c("lambda", "phi_inv"))

smr_pred <- cbind(as.data.frame(
  summary(
    fit,
    pars = "sim_cases",
    probs = c(0.05, 0.5, 0.95)
  )$summary),
  t=t[1:(n_times-1)], cases=synth_df$cases[1:(n_times-1)])
colnames(smr_pred) <- make.names(colnames(smr_pred)) # to remove % in the col names

c_posterior = "blue"
ggplot(smr_pred, mapping = aes(x = t)) +
  geom_ribbon(aes(ymin = X5., ymax = X95.), fill = c_posterior, alpha = 0.35) +
  geom_line(mapping = aes(y = X50.), color = c_posterior) + 
  geom_point(mapping = aes(y = cases)) +
  labs(x = "Day", y = "Cases") +
  coord_cartesian(ylim = c(0, NA))
```

```{r}
params_extract = rstan::extract(fit, c("lambda", "phi_inv")) %>%
  lapply(as.numeric) %>%
  as_tibble()
real_params_df = as.data.frame(real_params) %>%
  pivot_longer(everything())
params_extract %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = value)) +
  geom_density(color="steelblue", fill="steelblue", alpha=0.75) +
  geom_vline(data=real_params_df, aes(xintercept=value), linetype="dashed") +
  facet_wrap(vars(name), scales = "free") +
  labs(title = "Re-estimated posterior densities",
       subtitle = "Dashed line: simulated value")
```

## Parameter recovery comparison on synthetic data

Under ideal conditions, model fitting using the time series should recovery the original parameters with reasonable accuracy, but the Champagne 2022 method will have some error term resulting from seasonality.

### Reasonable scenarios

We define reasonable scenarios that reflect the assumptions of the Champagne model except for seasonality. For example, a range of transmission intensities and treatment capabilities. Data will be taken from oscillating or steady-state periods after the long-term trend has been stabilised as we are only relaxing the non-seasonal assumption of Champagne 2022.

Scenarios include sequences of scenarios. For example, low-transmission tropical relapse with a range of magnitudes of seasonality (peak-trough ratio from 0% to 100%). This sequence would demonstrate how the magnitude of seasonality impacts the accuracy of parameter recovery.

```{r}
ascertainment_rates = c(0.25, 0.5, 0.75, 1)[1]
radical_cure_rates = c(0.25, 0.5, 0.75, 1)[1]
transmission_rates = c(0.001, 0.01, 0.1, 1)
importation_rate = 0 # because constant importation makes less sense in seasonal transmission
population_size = 10000

data_scenarios = expand_grid(
  ascertainment_rates,
  radical_cure_rates,
  transmission_rates,
  importation_rate,
  population_size
)

generate_cases = function(alpha, beta, lambda, delta, N) {
  data = data_consts
  data$alpha = alpha
  data$beta = beta
  data$delta = delta
  data$N = N
  
  real_params = list(lambda=lambda, phi_inv=0.1)
  synth_data = simulate_data(
    file = model_champagne2022_seasonal,
    data_name = "dummy_data",
    input_data = data,
    param_values = real_params,
    vars = c("ts", "sim_cases", "susceptible")
  )
  synth_data_rds = readRDS(synth_data$datasets[1])
  indx <- sapply(synth_data_rds, length)
  synth_df = lapply(synth_data_rds, function(x) {length(x) = max(indx); x}) %>%
    as.data.frame() %>%
    drop_na()
  
}

cases_scenarios = lapply(seq_len(nrow(data_scenarios)), function(i) {
  dat = data_scenarios[i,]
  x = generate_cases(dat$ascertainment_rates, dat$radical_cure_rates, dat$transmission_rates, dat$importation_rate, dat$population_size)
})

data_scenarios$cases = lapply(cases_scenarios, function(x) {x$cases})
data_scenarios$ts = lapply(cases_scenarios, function(x) {x$ts})

# Display scenarios
data_scenarios %>%
  unnest(cols = c("ts", "cases")) %>%
  ggplot(aes(x = ts, y = cases, color=transmission_rates, group=transmission_rates)) +
  geom_line() +
  scale_color_gradient(trans = "log", breaks=10^seq(-5, 5))
data_scenarios
```

```{r}
# Solve using Champagne
mydata = data_scenarios %>%
  mutate(id = LETTERS[row_number()],
         h = sapply(cases, mean) * 30.4 / N,
         alpha = ascertainment_rates,
         beta = radical_cure_rates,
         rho = alpha,
         omega = 1,
         prop_import = 0,
         .keep = "none")
mydata = data_scenarios %>%
  mutate(id = LETTERS[row_number()],
         h = sapply(cases, mean) * 30.4 / N,
         alpha = 0.9,
         beta = 0.9,
         rho = 0.9,
         omega = 1,
         prop_import = 0,
         .keep = "none")
mydata_withR0RC=calibrate_vivax_equilibrium(df=mydata, f=data_consts$f, gamma=data_consts$gammal, r=data_consts$r, return.all = TRUE)
mydata_withR0RC
```

### Comparison of parameter recovery

On each scenario or sequence, recover the parameters using Champagne's solution on annual data and the typical ODE method. Show the resulting errors to the true parameter value.

```{r}
sim_scenarios = lapply(data_scenarios, function(x) {
  x
})

# Display true and recovered parameters
```

## Parameter recovery on real data

We test whether parameter recovery works on real datasets. We will find data from a variety of settings (e.g., transmission levels, remoteness, strains) to demonstrate generalisability.

Data:

- Hainan data (tropical China) but this has been difficult to acquire.
We will not be investigating Chinese Yunnan (southern mountainous) or Henan (central temperate) data which we do have because the Yunnan strain is not known to be tropical, and the Henan data is temperate (our current temperate model does not align with this data convincingly).
- Brazilian 'integrated data set', available per county or municipality and very detailed.

```{r}
data_hainan = list(NULL)

data_brazil = list(low = NULL,
                   med = NULL,
                   high = NULL)
```

### Outputs

The parameter fitting routing will be run for each real-world dataset.

```{r}
fit_brazil = lapply(data_brazil, function(x) {
  # perform Bayesian fit
})

# Show visual diagnostics to demonstrate that the model outputs actually reflect the observed data (this is not guaranteed because Champagne never used seasonal data)

# Show parameter posterior distributions
```

With the parameter posterior distributions, we can start to discuss outcomes. We expect that the main advancement here is demonstrating heterogeneity in epidemic parameters; while it is clear there is heterogeneity in prevalence, administrative data is not normally able to demonstrate this. As James highlighted, this also raises the question of whether multiple regions should comprise a hierarchical model. The Brazilian data is very comprehensive across regions and makes this logical, but I suggest exploring this after performing independent modelling first.

## Extension to include time-varying transmission levels

The Chinese and Brazilian datasets include longitudinal data for long enough to observe trends that must be due to changes in policy or environment Therefore, the seasonal Champagne model certainly will not be sufficient to explain this variation.

We will modify the Champagne model's transmission rate $\lambda$ to be time-varying, $\lambda(t)$. The functional form of $\lambda(t)$ is unclear but is constrained by the information available to fit it. For example, we will never know if a decrease in trend is due to natural decay to a low equilibrium, or due to a decreasing $\lambda(t)$. However, by finding a *reasonable* form, $\lambda(t)$ will account for long-term variation that cannot be explained by other parameters and we hope it will allow the other parameters to be recovered in scenarios where there is no form of static or dynamic steady-state at play.

At a minimum, $\lambda(t)$ will be a piecewise-constant or piecewise-linear function with breakpoints set manually when there are obvious changes in transmission intensity. This may prove sufficient. Other suggestions include particle filtering methods such as Kalman filtering.

```{r}
lambda = function(t, ...) {
  
}
```

